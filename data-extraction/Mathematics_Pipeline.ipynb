{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "959bd873-2f6b-4790-ba3a-c0698a98cfb2",
   "metadata": {},
   "source": [
    "# Implementation of Mathematics Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de68748-b8b8-49ee-8520-a2d0ec3af429",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install langchain-groq\n",
    "!pip install openai\n",
    "!pip install langchain-google-genai\n",
    "!pip install langchain-core "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222d38c9-c0d1-4c14-88f1-374f35c9cb00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "import inspect\n",
    "\n",
    "# Processing the AIMesaage and converting it to human Message\n",
    "\n",
    "from langchain_core.messages.ai import AIMessage\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09dca5c-69b4-4dc1-a745-6a0e8fa926fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_api_key=\"<----Your API Key---->\"\n",
    "groq_api_key=\"<----Your API Key---->\"\n",
    "model_name=\"llama3-70b-8192\"\n",
    "#model_name=\"gemini-pro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6578ac36-43eb-405d-a691-8019ff4e5d13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ChatGroq(temperature=0.7, \n",
    "                groq_api_key=groq_api_key, \n",
    "                model_name=model_name,\n",
    "                max_tokens=8192,\n",
    "                model_kwargs={\"top_p\": 0.7,#\"json_response\": False\n",
    "                             },\n",
    "                )\n",
    "\n",
    "#print(inspect.getsource(ChatGroq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced8ca06-6906-4f61-a231-da3522fcd263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI, HarmBlockThreshold, HarmCategory\n",
    "\n",
    "model = GoogleGenerativeAI(\n",
    "    model=model_name,\n",
    "    google_api_key=google_api_key,\n",
    "    safety_settings={\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d2984e-e2de-4480-991c-da000ece8109",
   "metadata": {},
   "source": [
    "## First chain to extact the ``Steps to Solve the problem``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12df5078-b78c-4895-a663-73232b82a625",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system=\" ###Context### \\\n",
    "You are an AI assistant that helps people solve Mathematics and Statistics. \\\n",
    "### Instruction ### \\\n",
    " 1. Provide List of the Steps to solve the question. Like` Step 1:,Step 2:` . \\\n",
    " Do not perform caculations and get do not get into details.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f86e7f-525a-411f-9c0a-3b732e30f5db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question=\"Q: \\\n",
    "Consider the following dataset for a binary classification problem in $\\mathbb{R}^{2}$ \\\n",
    "\\[x_{1}=[\\begin{matrix}1\\\\ 0\\end{matrix}],y_{1}=+1\\]\\\n",
    "\\[x_{2}=[\\begin{matrix}0\\\\ 1\\end{matrix}],y_{2}=+1\\]\\\n",
    "\\[x_{3}=[\\begin{matrix}-1\\\\ 0\\end{matrix}],y_{3}=-1\\]\\\n",
    "\\[x_{4}=[\\begin{matrix}0\\\\ -1\\end{matrix}],y_{4}=-1\\]\\\n",
    "Choose all linear classifiers that result in zero misclassifications on this dataset. Here, w is the weight vector for the linear classifier.\\\n",
    "A)  \\[w=[\\begin{matrix}1\\\\ 2\\end{matrix}]\\]\\\n",
    "B)  \\[w=[\\begin{matrix}10\\\\ 19\\end{matrix}]\\]\\\n",
    "C) \\[w=[\\begin{matrix}-1\\\\ -4\\end{matrix}]\\]\\\n",
    "D) \\[w=[\\begin{matrix}-5\\\\ 3\\end{matrix}]\\]\\\n",
    "E) \\[w=[\\begin{matrix}5\\\\ -3\\end{matrix}]\\]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d14b05d-69ef-4c7b-a6f0-1c7d2d16f4a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "human = \"{content}\"\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b58477-8fef-4cf9-96a1-19ede564ce34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = prompt | model #| output_parser\n",
    "output=await chain.ainvoke({\"content\": question }) ### Outputs AI message\n",
    "print(f'########## Model used : {model_name} #########')\n",
    "print(output.content)\n",
    "\n",
    "#print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10513de6-b308-4322-a63d-d76e2eba7b36",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Second chain to provide ``Steps as input to Solve the problem and Solution in the form of code``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351a37fd-338e-425a-9437-cc755c670713",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "steps = HumanMessage(content=question +\" \\n \"+ output.content) ### Converts ai message to human message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b46183b-ee6c-4d98-89fa-b51442672852",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(steps.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92686c8a-9fdc-4acb-94a7-92221fd35b5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input = steps.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537a6b7d-eb69-48c4-a565-7fffe7a25acd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system=\" ###Context### \\\n",
    "You are an AI assistant that helps people solve Mathematics and Statistics. \\\n",
    "### Instruction ### \\\n",
    " Provide the Python code to solve the Questions from the given instructions. \\\n",
    " Provide comment for each step in the code.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df72297-e33b-45b8-a04e-a5562a04e4f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "human = \"{content}\"\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])\n",
    "\n",
    "prompt_value = prompt.invoke({\"content\": input })\n",
    "\n",
    "\n",
    "chain = prompt | model\n",
    "code=await chain.ainvoke({\"content\": input })\n",
    "print(f'########## Model used : {model_name} #########')\n",
    "print(code.content)\n",
    "#print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8b056a-21bb-443b-a3dc-c9ab3476f1ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the data points and labels\n",
    "x1 = np.array([1, 0])\n",
    "y1 = 1\n",
    "x2 = np.array([0, 1])\n",
    "y2 = 1\n",
    "x3 = np.array([-1, 0])\n",
    "y3 = -1\n",
    "x4 = np.array([0, -1])\n",
    "y4 = -1\n",
    "\n",
    "# Define the options for the weight vectors\n",
    "options = [\n",
    "    np.array([1, 2]),\n",
    "    np.array([10, 19]),\n",
    "    np.array([-1, -4]),\n",
    "    np.array([-5, 3]),\n",
    "    np.array([5, -3])\n",
    "]\n",
    "\n",
    "# Initialize a list to store the correct options\n",
    "correct_options = []\n",
    "\n",
    "# Iterate over the options\n",
    "for w in options:\n",
    "    # Initialize a flag to check if the option results in zero misclassifications\n",
    "    zero_misclassifications = True\n",
    "    \n",
    "    # Iterate over the data points\n",
    "    for x, y in [(x1, y1), (x2, y2), (x3, y3), (x4, y4)]:\n",
    "        # Calculate the sign of w^T*x\n",
    "        sign = np.sign(np.dot(w, x))\n",
    "        \n",
    "        # Check if the sign matches the label\n",
    "        if sign != y:\n",
    "            zero_misclassifications = False\n",
    "            break\n",
    "    \n",
    "    # If the option results in zero misclassifications, add it to the correct options\n",
    "    if zero_misclassifications:\n",
    "        correct_options.append(w)\n",
    "\n",
    "# Print the correct options\n",
    "print(\"The correct options are:\")\n",
    "for w in correct_options:\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547271ab-f381-4346-b945-2423b20e8ec6",
   "metadata": {},
   "source": [
    "### Step 3 Proving the input to third chain for latex calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2443586-4ace-4c2a-9bfc-a625cb8e809f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input = human_message.content + \"\\n Solution : \"\n",
    "\n",
    "print(f'::::::::::::::::: Below is sample input to the chain ::::::::::::')\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de98a87d-ad9c-4535-8c5f-756d2885e953",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system=\" ###Context### \\\n",
    "You are an AI assistant that helps people solve Mathematics and Statistics. \\\n",
    "### Instruction ### \\\n",
    " Provide the latex code to solve the Questions from the given instructions. \\\n",
    " Use code interpreter to perform calculations while solving the questions. \\\n",
    " Use the steps provided in the question to provide the solution. \\\n",
    "### Output ### \\\n",
    "Only provide the latex document in the output. \\\n",
    "Please include the dependencies used by the latex cod in \\\\usepackage. \\\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5e4c71-3d76-4f81-9066-238e5e1d812a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "human = \"{content}\"\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])\n",
    "\n",
    "prompt_value = prompt.invoke({\"content\": input })\n",
    "\n",
    "\n",
    "chain = prompt | model\n",
    "content=await chain.ainvoke({\"content\": input })\n",
    "print(f'########## Model used : {model_name} #########')\n",
    "print(content.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
